{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import StratifiedShuffleSplit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Time series data tranformation for use in the 1D CNN model for event type prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>P-PDG</th>\n",
       "      <th>P-TPT</th>\n",
       "      <th>T-TPT</th>\n",
       "      <th>P-MON-CKP</th>\n",
       "      <th>T-JUS-CKP</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>27897490.0</td>\n",
       "      <td>19824230.0</td>\n",
       "      <td>125.685900</td>\n",
       "      <td>4059666.0</td>\n",
       "      <td>97.55283</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>27897450.0</td>\n",
       "      <td>19824230.0</td>\n",
       "      <td>125.685900</td>\n",
       "      <td>4059666.0</td>\n",
       "      <td>97.55283</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>27897360.0</td>\n",
       "      <td>19824230.0</td>\n",
       "      <td>125.685900</td>\n",
       "      <td>4059666.0</td>\n",
       "      <td>97.55283</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>27897430.0</td>\n",
       "      <td>19824230.0</td>\n",
       "      <td>125.685900</td>\n",
       "      <td>4059666.0</td>\n",
       "      <td>97.55282</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>27897500.0</td>\n",
       "      <td>19824230.0</td>\n",
       "      <td>125.685900</td>\n",
       "      <td>4059666.0</td>\n",
       "      <td>97.55282</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26994</th>\n",
       "      <td>33700360.0</td>\n",
       "      <td>28074090.0</td>\n",
       "      <td>3.413923</td>\n",
       "      <td>4002707.0</td>\n",
       "      <td>28.00641</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26995</th>\n",
       "      <td>33700220.0</td>\n",
       "      <td>28074160.0</td>\n",
       "      <td>3.413754</td>\n",
       "      <td>4002710.0</td>\n",
       "      <td>27.97934</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26996</th>\n",
       "      <td>33700150.0</td>\n",
       "      <td>28074160.0</td>\n",
       "      <td>3.413741</td>\n",
       "      <td>4002710.0</td>\n",
       "      <td>27.95308</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26997</th>\n",
       "      <td>33700210.0</td>\n",
       "      <td>28074220.0</td>\n",
       "      <td>3.413593</td>\n",
       "      <td>4002719.0</td>\n",
       "      <td>27.92784</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26998</th>\n",
       "      <td>33700220.0</td>\n",
       "      <td>28074120.0</td>\n",
       "      <td>3.413797</td>\n",
       "      <td>4002730.0</td>\n",
       "      <td>27.90521</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>26999 rows Ã— 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            P-PDG       P-TPT       T-TPT  P-MON-CKP  T-JUS-CKP  class\n",
       "0      27897490.0  19824230.0  125.685900  4059666.0   97.55283      0\n",
       "1      27897450.0  19824230.0  125.685900  4059666.0   97.55283      0\n",
       "2      27897360.0  19824230.0  125.685900  4059666.0   97.55283      0\n",
       "3      27897430.0  19824230.0  125.685900  4059666.0   97.55282      0\n",
       "4      27897500.0  19824230.0  125.685900  4059666.0   97.55282      0\n",
       "...           ...         ...         ...        ...        ...    ...\n",
       "26994  33700360.0  28074090.0    3.413923  4002707.0   28.00641      8\n",
       "26995  33700220.0  28074160.0    3.413754  4002710.0   27.97934      8\n",
       "26996  33700150.0  28074160.0    3.413741  4002710.0   27.95308      8\n",
       "26997  33700210.0  28074220.0    3.413593  4002719.0   27.92784      8\n",
       "26998  33700220.0  28074120.0    3.413797  4002730.0   27.90521      8\n",
       "\n",
       "[26999 rows x 6 columns]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filename = os.getcwd()+'/data/oil_wells_data.csv'\n",
    "df = pd.read_csv(filename)\n",
    "# delete all-null columns\n",
    "df = df.dropna(axis=1, how='all')\n",
    "# delete timestamp column\n",
    "df = df.drop(['timestamp'], axis=1)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Normalizing the data is important for the 1D CNN model to work properly. We have 5 attributes with totally different scales. Without normalization, the model will be biased towards the attributes with larger scales (will learn larger weights for them)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before normalization, we will first split the data into training and validation sets in order to avoid data leakage between the sets. Then we will create new instances of the time series data by sliding a window over the data. Only after this we will normalize the data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order for the classes to be balanced both in the training and test sets, we will use stratified splitting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "split = StratifiedShuffleSplit(n_splits=1, test_size=0.2, random_state=42)\n",
    "for train_index, test_index in split.split(df, df['class']):\n",
    "    strat_train_set = df.loc[train_index]\n",
    "    strat_test_set = df.loc[test_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "class\n",
       "8      0.592593\n",
       "108    0.340741\n",
       "0      0.066667\n",
       "Name: count, dtype: float64"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "strat_test_set['class'].value_counts() / len(strat_test_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "class\n",
       "8      0.592578\n",
       "108    0.340753\n",
       "0      0.066669\n",
       "Name: count, dtype: float64"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['class'].value_counts() / len(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the sliding window to create new instances that will be used for convolutions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "timeframe = 40\n",
    "stride = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sliding_window(df, timeframe=40, stride=1):\n",
    "    new_instances = [] # list of windows for each column\n",
    "    new_labels = [] # list of windows for the label\n",
    "\n",
    "    for col in df.columns[:-1]:  # we don't want to create windows for the label\n",
    "        # create windows by shifting from the bottom of every column\n",
    "        windows = [df[col].shift(-i) for i in range(timeframe)] \n",
    "        \n",
    "        # an instance is a set of windows for all columns\n",
    "        # instances do not overlap\n",
    "        # we only take instances that have all their values (exclude timeframe - 1 rows)\n",
    "        instances = np.vstack(windows).T[:-timeframe+1:stride]\n",
    "        new_instances.append(instances)\n",
    "\n",
    "    labels_windows = [df[df.columns[-1]].shift(-i) for i in range(timeframe)]\n",
    "    new_labels = np.vstack(labels_windows).T[:-timeframe+1:stride]\n",
    "\n",
    "    return np.stack(new_instances, axis=-1), new_labels\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dimensions of transformed training instances: (21560, 40, 5)\n",
      "Dimensions of transformed training labels : (21560, 40)\n",
      "Dimensions of transformed test instances: (5361, 40, 5)\n",
      "Dimensions of transformed test labels : (5361, 40)\n"
     ]
    }
   ],
   "source": [
    "X_train, y_train = sliding_window(strat_train_set)\n",
    "\n",
    "X_test, y_test = sliding_window(strat_test_set)\n",
    "\n",
    "print(\"Dimensions of transformed training instances:\", X_train.shape)\n",
    "print(\"Dimensions of transformed training labels :\", y_train.shape)\n",
    "print(\"Dimensions of transformed test instances:\", X_test.shape)\n",
    "print(\"Dimensions of transformed test labels :\", y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(21560, 40)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "# create a MinMaxScaler instance\n",
    "scaler = MinMaxScaler()\n",
    "\n",
    "# reshape X_train to 2D array (instances, features)\n",
    "X_train_reshaped = X_train.reshape(-1, X_train.shape[-1])\n",
    "\n",
    "X_train_normalized = scaler.fit_transform(X_train_reshaped)\n",
    "\n",
    "# reshape back to 3D array (instances, timeframe, features)\n",
    "X_train_normalized = X_train_normalized.reshape(X_train.shape)\n",
    "\n",
    "X_test_reshaped = X_test.reshape(-1, X_test.shape[-1])\n",
    "X_test_normalized = scaler.transform(X_test_reshaped)\n",
    "X_test_normalized = X_test_normalized.reshape(X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transformed instances saved to: ./data/X_train_transformed.csv\n",
      "Transformed labels saved to: ./data/y_train_transformed.csv\n"
     ]
    }
   ],
   "source": [
    "X_train_df = pd.DataFrame(X_train_normalized.reshape(X_train.shape[0], -1)) # reshape X_test into 2D (instances, features*window)\n",
    "y_df = pd.DataFrame(y_train)\n",
    "X_train_file_path = \"./data/X_train_transformed.csv\"\n",
    "y_file_path = \"./data/y_train_transformed.csv\"\n",
    "\n",
    "X_train_df.to_csv(X_train_file_path, index=False, sep=' ')\n",
    "y_df.to_csv(y_file_path, index=False, sep=' ')\n",
    "\n",
    "print(\"Transformed instances saved to:\", X_train_file_path)\n",
    "print(\"Transformed labels saved to:\", y_file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transformed instances saved to: ./data/X_test_transformed.csv\n",
      "Transformed labels saved to: ./data/y_test_transformed.csv\n"
     ]
    }
   ],
   "source": [
    "X_test_df = pd.DataFrame(X_test_normalized.reshape(X_test.shape[0], -1))\n",
    "y_df = pd.DataFrame(y_test)\n",
    "\n",
    "X_test_file_path = \"./data/X_test_transformed.csv\"\n",
    "y_file_path = \"./data/y_test_transformed.csv\"\n",
    "\n",
    "X_test_df.to_csv(X_test_file_path, index=False, sep=' ')\n",
    "y_df.to_csv(y_file_path, index=False, sep=' ')\n",
    "\n",
    "print(\"Transformed instances saved to:\", X_test_file_path)\n",
    "print(\"Transformed labels saved to:\", y_file_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
